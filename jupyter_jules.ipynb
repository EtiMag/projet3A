{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGEdB-G5_i_N"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_5c2COe_nKJ"
      },
      "source": [
        "Nous avons travaillé sur les méthodes proposées dans l'article *Dimension Independent Matrix Square using MapReduce (DIMSUM)*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq6cxbCrACyJ"
      },
      "source": [
        "L'article développe une solution générale pour pour calculer le produit $A^TA$ avec $A$ une matrice sparse de taille $n \\times m$ avec $m >> n$.  On considère typiquement des matrices de grande taille avec $m \\approx 10^{13}$ et $n \\approx 10^4$. L'algorithme proposé fait appel à la méthode MapReduce pour paralléliser les calculs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8sHuAxoBKNF"
      },
      "source": [
        "La plupart des méthodes de calculs de $A^TA$ nécessitent d'avoir accès à la totalité de la matrice $A$ sur une seule machine ou bien d'échanger un grand nombre d'informations entre les machines, ce qui n'est pas faisable pour les valeurs de $m$ considérées. Une matrice de cette taille ne peut être stockée ou streamée sur une seule machine, ce qui nécessite d'utiliser un algorithme adapté."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb0ZVGO8CD-p"
      },
      "source": [
        "MapReduce est utilisé pour gérer une grande quantité de données (ici la matrice de taille $m \\times n$) en distribuant le calcul sur plusieurs machines. L'algorithme présenté se base sur la décomposition en valeurs singulières d'une matrice de taille $m \\times n$ avec au plus $L$ valeurs non-nulles par ligne (sparsité). La décomposition en valeurs singulirères (SVD) de $A$ s'écrit: $A = UΣV^T$, avec $U$ et $V$ deux matrices unitaires de tailles $m \\times m$ et $n \\times n$. L'article développe un algorithme permettant de calculer le produit $A^TA$ sans dépendance à $m$ et fournit une borne supérieure pour l'erreur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2j1EdD4lcr1"
      },
      "source": [
        "**Objectif:** Calculer le produit $A^TA$ avec $A$ une matrice $m \\times n$  ($m >> n$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLGZXebamBhX"
      },
      "source": [
        "# **I. Algorithmes et implémentations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i3Yb9QEM14o"
      },
      "source": [
        "*(Les codes proposés dans cette parties ne sont pas utilisables directement. La version utilisable de ces codes se trouve dans la partie dédiée aux tests et à la présentation du code)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_duLiENjN9WK"
      },
      "source": [
        "## **A. Algorithmes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DXaTTuwlzXx"
      },
      "source": [
        "### **1) Version brute**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpiUXJYyqfE2"
      },
      "source": [
        "Une première méthode de calcul consiste en une implémentation non-parallélisée du calcul."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5JbQdY3lTIu"
      },
      "source": [
        "**Algorithme brut**\n",
        "\n",
        "\n",
        "**for** all $r_i$ in A:  \n",
        "$\\space\\space$**for** all pairs ($a_{ij}$,$a_{ik}$) in $r_i$:  \n",
        "$\\space\\space\\space\\space$ Emit ($c_i, c_j$) $→$ $a_{ij} a_{ik}$  \n",
        "$\\space\\space$**end for**  \n",
        "**end for**  \n",
        "**Output** C\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZqh1E5ktXwg"
      },
      "source": [
        "En pratique on utilise **Numpy** pour effectuer ce calcul \"brut\"\n",
        "\n",
        "\n",
        "```\n",
        "N = A.T.dot(A)\n",
        "```\n",
        "\n",
        "Comme évoqué dans l'introduction, cette implémentation n'est pas utilisable en pratique pour les matrices considérées (stockage de la matrice et temps de calcul)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdwhbHSkv3jI"
      },
      "source": [
        "### **2) Version parallèle naïve**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXFuWPXywLTF"
      },
      "source": [
        "Une première version naïve faisant appel à un mapper et un reducer est proposée dans le papier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iss5JZlcwV36"
      },
      "source": [
        "**Mapper naïf $(r_i)$**  \n",
        "$\\space\\space\\space\\space$**for** all pairs ($a_{ij}$,$a_{ik}$) in $r_i$:  \n",
        "$\\space\\space\\space\\space\\space\\space$ Emit ($c_i, c_j$) $→$ $a_{ij} a_{ik}$  \n",
        "$\\space\\space\\space\\space$**end for**\n",
        "  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Reducer naïf $((c_i,c_j),<v_1, … , v_R>)$**  \n",
        "$\\space\\space\\space\\space$**Output** $c_i^T c_j → ∑_{i = 1}^R v_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQBJNnLzDAh"
      },
      "source": [
        "En pratique, nous avons utilisé **Numpy** pour implémenter simplement cette version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RBTDuKkzQ1w"
      },
      "outputs": [],
      "source": [
        "def mapper(mat, norms_array, gamma):\n",
        "    return mat.T@mat\n",
        "\n",
        "\n",
        "def reducer(mat_list, norms_array, gamma):\n",
        "    return sum(mat_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBKvgJBGzhrk"
      },
      "source": [
        "La manière naïve d'effectuer le calcul de $A^TA$ consiste à calculer tous les produits entre les colonnes de la matrice $A$ et à paralléliser le calcul.\n",
        "On peut voir que l'implémentation naïve de MapReduce a une compléxité en $O(mL^2)$, ce qui est infaisable pour les matrices étudiées. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFmWtSD6l4H1"
      },
      "source": [
        "### **3) Version parallèle efficace**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QLp3rFE0Kwc"
      },
      "source": [
        "Pour un algorithme MapReduce, il existe deux sources principales de complexité:\n",
        "\n",
        "\n",
        "*   une complexité liée aux communications entre les machines (\"shuffle-size\")\n",
        "*   une complexité liée à la surcharge potentielle d'une matrice (\"reduce-key\")\n",
        "\n",
        "Il est possible de réduire significativement les deux complexités avec l'algorithme DIMSUM proposé dans l'article. Dans ce cas, le reducer renvoie une variable aléatoire dont l'espérance est une normalisation des paramètres de $A^TA$. Il est en particulier possible de montrer que, pour un seuil ϵ donné, la complexité liée à la charge d'une machine (\"reduce-key\") est en $O(\\frac{n^2}{ϵ^2})$, donc indépendante de $m$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvx-e4VJ9nv"
      },
      "source": [
        "On choisit dans ce cas un $\\gamma$, l'algorithme efficace s'écrit comme suit:\n",
        "\n",
        "**Mapper DIMSUM $(r_i)$**  \n",
        "$\\space\\space\\space\\space$**for** all pairs ($a_{ij}$,$a_{ik}$) in $r_i$:  \n",
        "$\\space\\space\\space\\space\\space\\space$ With probability $min(1,\\gamma \\frac{1}{||c_j|| \\cdot ||c_k||})$    \n",
        "$\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space$ Emit ($c_i, c_j$) $→$ $a_{ij} a_{ik}$  \n",
        "$\\space\\space\\space\\space$**end for**\n",
        "  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Reducer DIMSUM $((c_i,c_j),<v_1, … , v_R>)$**  \n",
        "$\\space\\space\\space\\space$**Output** $b_{ij} → \\frac{1}{min(\\gamma,||c_j|| \\cdot ||c_k||)} ∑_{i = 1}^R v_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRSsReWb7EJw"
      },
      "source": [
        "En voici, une version en Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL1fXFHRMzCM"
      },
      "outputs": [],
      "source": [
        "def mapper(mat, norms_array, gamma):\n",
        "    gamma_copy = gamma\n",
        "    nrow, ncol = mat.shape\n",
        "    output = np.zeros((ncol, ncol)) # note that ncol << nrow, so the for loops are OK\n",
        "    for i_output in range(ncol):\n",
        "        for j_output in range(ncol):\n",
        "            # randomly choose pairs\n",
        "            random_values = np.random.rand(nrow)\n",
        "            probas = gamma_copy/(norms_array[i_output]*norms_array[j_output])*np.ones((nrow,))\n",
        "            bool_vect = (probas < random_values)\n",
        "            # sum chosen pairs\n",
        "            output[i_output, j_output] = np.sum(mat[bool_vect, i_output]*mat[bool_vect, j_output])\n",
        "    return output\n",
        "\n",
        "\n",
        "def reducer(mat_list, norms_array, gamma):\n",
        "    return 1/np.minimum(np.outer(norms_array, norms_array), gamma)*sum(mat_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ7Qs94iNseb"
      },
      "source": [
        "## **B. Résultats théoriques**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBS0ESCzUSm1"
      },
      "source": [
        "A compléter\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT55ZAbrOZ3r"
      },
      "source": [
        "## **C. Technologies utilisées** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lbsv4EfS8v6"
      },
      "source": [
        "Dans une logique d'optimisation de la performance de nos algorithmes, nous avons comparé l'usage de 2 structures de données différentes pour stocker les matrices: \n",
        "\n",
        "\n",
        "*   Stockage sous forme de **dictionnaires Python**\n",
        "*   Stockage sous forme d'**arrays Numpy**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmLRi0J8Nvn3"
      },
      "source": [
        "Comme suggéré dans l'article nous avons utilisé un algorithme MapReduce pour gérer en parallèle le grand nombre d'entrées de la matrice A. La très grande taille de la matrice (plusieurs gigaoctets) ainsi que la contrainte temporelle nous ont amenés à distribuer le calcul via les algorithmes présentés dans la partie I.A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khUQA7T7Ofjk"
      },
      "source": [
        "L'implémentation des algorithmes a été effectuée avec Python en faisant appel aux bibliothèques ```multirocessing``` et ```threading``` dont nous avons cherché à comparer les performances sur différentes matrices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzW_msRNSyNQ"
      },
      "source": [
        "**Multiprocessing**  \n",
        "Ce package permet le recours à des sous-process pour effectuer des calculs en parallèle. Il propose en particulier la fonction ```Pool``` pour gérer simplement les multiples sous-process utilisés\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF8sexVLS1uT"
      },
      "source": [
        "**Threading**  \n",
        "Ce package permet de générer et de gérer différents threads pour effectuer les calculs en parallèle. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4-U188PRrqm"
      },
      "source": [
        "La bibliothèque ```numpy``` a été utilisée pourn définir et manipuler les matrices plus simplement. Il est a noter que ```numpy``` fait déjà appel à des méthodes d'optimisation de la performance lors de calculs de matrices. Ce que nous avons pu confirmer en étudiant l'utilisation des différents coeurs de nos machines lors de l'appel à une version non-parallélisée du calcul. Pour résoudre ce problème et contrôler nous-même la performance, nous avons imposé à ```numpy``` de ne faire appel qu'à un seul coeur lors de l'execution, afin de contrôler la parallèlisation indépendemment.\n",
        "\n",
        "\n",
        "```\n",
        "# force numpy to use only a single processor, by changing the environment of the underlying libraries\n",
        "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "import numpy as np\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II8dHoc1U7DR"
      },
      "source": [
        "# **Conclusion**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_duLiENjN9WK"
      ],
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# force numpy to use only a single processor, by changing the environment of the underlying libraries\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import numpy as np\n",
    "\n",
    "# libraries for multiprocessing\n",
    "import multiprocessing as mp\n",
    "import threading as th\n",
    "\n",
    "from scipy.stats import unitary_group\n",
    "import random\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main execution procedure, taking the matrix, mapper and reducer as input\n",
    "\n",
    "def execute(big_matrix, mapper, reducer, type = \"T\", n_split = 6, gamma = 1):\n",
    "    \"\"\"Execute map - reduce algorithm based on input mapper and reducer, using Threads / Processes depending on type,\n",
    "    returns a tuple (result_matrix, execution_time)\"\"\"\n",
    "    (nrow_big_matrix, ncol_big_matrix) = big_matrix.shape\n",
    "    sub_matrix_list = chunkify(big_matrix, n_split=n_split)\n",
    "    norms_array = norm(big_matrix)\n",
    "\n",
    "    # initialize execution time\n",
    "    start_time = 0\n",
    "    end_time = 0\n",
    "\n",
    "    if type == \"P\":\n",
    "        pool = mp.Pool(n_split)\n",
    "\n",
    "        # create list of arguments\n",
    "        args_list = []\n",
    "        for sub_mat in sub_matrix_list:\n",
    "            gamma_copy = gamma + 0.\n",
    "            args_list.append((sub_mat, norms_array.copy(), gamma_copy))\n",
    "\n",
    "        start_time = time.time()\n",
    "        # map\n",
    "        mapped = pool.starmap(mapper, args_list)\n",
    "        # reduce\n",
    "        result = reducer(mapped, norms_array, gamma)\n",
    "        end_time = time.time()\n",
    "        return result, end_time - start_time\n",
    "\n",
    "    if type == \"T\":\n",
    "        thread_list = []\n",
    "        # allocate output\n",
    "        sub_output_list = []\n",
    "        for i in range(n_split):\n",
    "            sub_output_list.append(np.zeros((ncol_big_matrix, ncol_big_matrix)))\n",
    "        start_time = time.time()\n",
    "\n",
    "        # define thread content\n",
    "        def thread_content(mapper, sub_matrix, sub_output, norms_array, gamma):\n",
    "            \"\"\"Calls the mapper on the sub_matrix and copies the values in sub_output\"\"\"\n",
    "            sub_output[:, :] = mapper(sub_matrix, norms_array, gamma)\n",
    "\n",
    "        # start threads\n",
    "        for i in range(n_split):\n",
    "            gamma_copy = gamma + 0. # necessary in order to copy the gamma value to avoid GIL\n",
    "            args = (mapper, sub_matrix_list[i], sub_output_list[i], norms_array.copy(), gamma_copy)\n",
    "            thread_current = th.Thread(target=thread_content, args=args)\n",
    "            thread_current.start()\n",
    "            thread_list.append(thread_current)\n",
    "        # Wait until all threads are finished\n",
    "        for thread in thread_list:\n",
    "            thread.join()\n",
    "\n",
    "        # reduce\n",
    "        result = reducer(sub_output_list, norms_array, gamma)\n",
    "        end_time = time.time()\n",
    "        return result, end_time - start_time\n",
    "\n",
    "    if not(isinstance(type, str)):\n",
    "        raise TypeError(\"type must be an instance of str\")\n",
    "    raise ValueError(\"type must be either T for threads or P for processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_mapper(mat, norms_array, gamma):\n",
    "    return mat.T@mat\n",
    "\n",
    "\n",
    "def naive_reducer(mat_list, norms_array, gamma):\n",
    "    return sum(mat_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_mapper(mat, norms_array, gamma):\n",
    "    gamma_copy = gamma\n",
    "    nrow, ncol = mat.shape\n",
    "    output = np.zeros((ncol, ncol)) # note that ncol << nrow, so the for loops are OK\n",
    "    for i_output in range(ncol):\n",
    "        for j_output in range(ncol):\n",
    "            # randomly choose pairs\n",
    "            random_values = np.random.rand(nrow)\n",
    "            probas = gamma_copy/(norms_array[i_output]*norms_array[j_output])*np.ones((nrow,))\n",
    "            bool_vect = (probas < random_values)\n",
    "            # sum chosen pairs\n",
    "            output[i_output, j_output] = np.sum(mat[bool_vect, i_output]*mat[bool_vect, j_output])\n",
    "    return output\n",
    "\n",
    "\n",
    "def paper_reducer(mat_list, norms_array, gamma):\n",
    "    return 1/np.minimum(np.outer(norms_array, norms_array), gamma)*sum(mat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunkify(Mat, n_split):\n",
    "    \"\"\"Splits the matrix Mat into nsplit matrices, returns a list of np.ndarray\"\"\"\n",
    "    (nrow, ncol) = Mat.shape\n",
    "    indexes = (nrow // n_split) * np.arange(1, n_split)\n",
    "    Mat_list = np.vsplit(Mat, indexes)\n",
    "    assert len(Mat_list) == n_split\n",
    "    return Mat_list\n",
    "\n",
    "\n",
    "# create a sparse matrix\n",
    "def create_big_matrix(nrow_big_matrix, ncol_big_matrix, nonzero):\n",
    "    assert ncol_big_matrix >= nonzero\n",
    "    A = np.zeros((nrow_big_matrix, ncol_big_matrix))\n",
    "    for i in tqdm.tqdm(range(nrow_big_matrix)):\n",
    "        nonzero_index = random.sample(list(range(ncol_big_matrix)), k=nonzero)\n",
    "        values = np.random.rand(nonzero)\n",
    "        A[i, nonzero_index] = values\n",
    "    return A\n",
    "\n",
    "def time_basic(big_matrix):\n",
    "    start_time = time.time()\n",
    "    result = big_matrix.T@big_matrix\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "\n",
    "### Define several norms\n",
    "\n",
    "#Recall that in finite dimension, all norms are equivalent\n",
    "def max_diff(matrix1, matrix2):\n",
    "    \"\"\"Returns the maximum absolute difference between matrix1 and matrix2 (Linf distance)\"\"\"\n",
    "    return np.max(np.absolute(matrix1 - matrix2))\n",
    "\n",
    "def norm(Mat):\n",
    "    \"\"\"returns an array with the norm of the columns of matrix mat\"\"\"\n",
    "    return np.sqrt(np.sum(np.square(Mat), axis=0))\n",
    "\n",
    "def distance(mat1, mat2, norm = None):\n",
    "    # return the distance between 2 matrix using different norms:\n",
    "    # norm = \n",
    "        # 'fro' for the Froebenius norm\n",
    "        # 'nuc' for the nuclear norm\n",
    "        #  inf  for the spectral norm\n",
    "    return np.linalg.norm(mat1-mat2,ord = norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 43265.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big matrix size = (1000, 50)\n",
      "Big matrix rank = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create big matrix (input)\n",
    "nrow_big_matrix, ncol_big_matrix = int(1e3), 50\n",
    "big_matrix = create_big_matrix(nrow_big_matrix=nrow_big_matrix, ncol_big_matrix=ncol_big_matrix, nonzero = 3)\n",
    "\n",
    "# check rank\n",
    "print(\"Big matrix size =\", big_matrix.shape)\n",
    "print(\"Big matrix rank =\", np.linalg.matrix_rank(big_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.\n",
    "\n",
    "result_parallel, exec_time_parallel = execute(big_matrix=big_matrix,\n",
    "                                              mapper=naive_mapper,\n",
    "                                              reducer=naive_reducer,\n",
    "                                              type=\"P\",\n",
    "                                              n_split=6,\n",
    "                                              gamma=gamma)\n",
    "\n",
    "# display execution time\n",
    "print(\"Execution time parallel=\", exec_time_parallel)\n",
    "\n",
    "# compare with basic approach\n",
    "result_basic, exec_time_basic = time_basic(big_matrix)\n",
    "print(\"Execution time basic=\", exec_time_basic)\n",
    "print(\"Distance between results\", distance(result_basic, result_parallel, norm = float(\"Inf\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mesures de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 generate big matrices to test\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
